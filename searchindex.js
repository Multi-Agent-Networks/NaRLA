Search.setIndex({docnames:["getting_started/installing","index","narla/environments","narla/history","narla/multi_agent_network","narla/neurons","narla/rewards","narla/runner","narla/settings","welcome"],envversion:{"sphinx.domains.c":2,"sphinx.domains.changeset":1,"sphinx.domains.citation":1,"sphinx.domains.cpp":4,"sphinx.domains.index":1,"sphinx.domains.javascript":2,"sphinx.domains.math":2,"sphinx.domains.python":3,"sphinx.domains.rst":2,"sphinx.domains.std":2,"sphinx.ext.intersphinx":1,"sphinx.ext.todo":2,"sphinx.ext.viewcode":1,nbsphinx:4,sphinx:56},filenames:["getting_started/installing.rst","index.rst","narla/environments.rst","narla/history.rst","narla/multi_agent_network.rst","narla/neurons.rst","narla/rewards.rst","narla/runner.rst","narla/settings.rst","welcome.rst"],objects:{"narla.Settings":[[8,1,1,"","as_dictionary"],[8,2,1,"","batch_size"],[8,2,1,"","device"],[8,2,1,"","environment"],[8,2,1,"","gpu"],[8,2,1,"","learning_rate"],[8,2,1,"","maximum_episodes"],[8,2,1,"","neuron_type"],[8,2,1,"","number_of_layers"],[8,2,1,"","number_of_neurons_per_layer"],[8,2,1,"","render"],[8,2,1,"","results_directory"],[8,2,1,"","reward_type"],[8,2,1,"","save_every"],[8,1,1,"","to_command_string"],[8,2,1,"","trial_id"]],"narla.environments":[[2,0,1,"","ActionSpace"],[2,4,1,"","AvailableEnvironments"],[2,0,1,"","Environment"],[2,0,1,"","GymEnvironment"],[2,4,1,"","GymEnvironments"]],"narla.environments.ActionSpace":[[2,3,1,"","number_of_actions"],[2,1,1,"","sample"],[2,3,1,"","shape"]],"narla.environments.Environment":[[2,3,1,"","action_space"],[2,3,1,"","episode_reward"],[2,3,1,"","observation_size"],[2,1,1,"","reset"],[2,1,1,"","step"]],"narla.environments.GymEnvironment":[[2,3,1,"","observation_size"],[2,1,1,"","reset"],[2,1,1,"","step"]],"narla.environments.GymEnvironments":[[2,2,1,"","CART_POLE"],[2,2,1,"","MOUNTAIN_CAR"]],"narla.history":[[3,0,1,"","History"]],"narla.history.History":[[3,1,1,"","clear"],[3,1,1,"","get"],[3,1,1,"","record"],[3,1,1,"","sample"],[3,1,1,"","to_data_frame"]],"narla.multi_agent_network":[[4,0,1,"","Layer"],[4,0,1,"","MultiAgentNetwork"]],"narla.multi_agent_network.Layer":[[4,1,1,"","act"],[4,1,1,"","distribute_to_neurons"],[4,3,1,"","layer_output"],[4,1,1,"","learn"],[4,3,1,"","number_of_neurons"]],"narla.multi_agent_network.MultiAgentNetwork":[[4,1,1,"","act"],[4,1,1,"","distribute_to_layers"],[4,3,1,"","history"],[4,1,1,"","learn"],[4,1,1,"","record"]],"narla.neurons":[[5,0,1,"","Network"],[5,0,1,"","Neuron"]],"narla.neurons.Network":[[5,1,1,"","forward"],[5,2,1,"","training"]],"narla.neurons.Neuron":[[5,1,1,"","act"],[5,3,1,"","history"],[5,1,1,"","learn"],[5,1,1,"","record"]],"narla.neurons.actor_critic":[[5,0,1,"","Network"],[5,0,1,"","Neuron"]],"narla.neurons.actor_critic.Network":[[5,1,1,"","forward"],[5,2,1,"","training"]],"narla.neurons.actor_critic.Neuron":[[5,1,1,"","act"],[5,1,1,"","get_returns"],[5,1,1,"","learn"]],"narla.neurons.deep_q":[[5,0,1,"","Network"],[5,0,1,"","Neuron"]],"narla.neurons.deep_q.Network":[[5,1,1,"","clone"],[5,1,1,"","forward"],[5,2,1,"","training"]],"narla.neurons.deep_q.Neuron":[[5,1,1,"","act"],[5,1,1,"","learn"],[5,1,1,"","sample_history"],[5,1,1,"","update_target_network"]],"narla.neurons.policy_gradient":[[5,0,1,"","Network"],[5,0,1,"","Neuron"]],"narla.neurons.policy_gradient.Network":[[5,1,1,"","clone"],[5,1,1,"","forward"],[5,2,1,"","training"]],"narla.neurons.policy_gradient.Neuron":[[5,1,1,"","act"],[5,1,1,"","get_returns"],[5,1,1,"","learn"]],"narla.rewards":[[6,0,1,"","ActiveNeurons"],[6,0,1,"","LayerSparsity"],[6,0,1,"","Reward"]],"narla.rewards.ActiveNeurons":[[6,1,1,"","compute"]],"narla.rewards.LayerSparsity":[[6,1,1,"","compute"]],"narla.rewards.Reward":[[6,1,1,"","compute"]],"narla.runner":[[7,0,1,"","Job"],[7,0,1,"","Runner"],[7,0,1,"","RunnerSettings"]],"narla.runner.Job":[[7,1,1,"","is_done"]],"narla.runner.Runner":[[7,1,1,"","execute"],[7,1,1,"","is_done"]],"narla.runner.RunnerSettings":[[7,1,1,"","as_dictionary"],[7,2,1,"","environments"],[7,2,1,"","gpus"],[7,2,1,"","jobs_per_gpu"],[7,2,1,"","learning_rates"],[7,2,1,"","neuron_types"],[7,2,1,"","number_of_layers"],[7,2,1,"","number_of_neurons_per_layer"],[7,1,1,"","product"],[7,2,1,"","reward_types"],[7,2,1,"","settings"],[7,1,1,"","to_command_string"]],narla:[[8,0,1,"","Settings"]]},objnames:{"0":["py","class","Python class"],"1":["py","method","Python method"],"2":["py","attribute","Python attribute"],"3":["py","property","Python property"],"4":["py","enum","Python enum"]},objtypes:{"0":"py:class","1":"py:method","2":"py:attribute","3":"py:property","4":"py:enum"},terms:{"0":[5,6,7,8],"0001":[5,7,8],"01":5,"1":7,"10":7,"1000":[7,8],"10000":[3,7,8],"128":[5,7,8],"15":[7,8],"2":[6,7,8],"8":0,"abstract":[5,6],"class":[2,3,4,5,6,7,8],"enum":2,"float":[2,4,5,7,8],"function":5,"int":[2,3,4,5,7,8],"return":[2,3,4,5,6,7,8],"true":[2,7,8],"while":5,A:[4,7],If:[2,3,7,8],The:5,Will:7,access:[2,3,4,5],across:7,act:[4,5],action:[2,4,5],action_spac:2,activ:6,actor_crit:[7,8],actorcrit:5,advanc:2,afterward:5,agent:0,alia:0,all:[3,5,7],all_set:7,although:5,alwai:[7,8],an:[2,3,4,5,7],append:3,appropri:6,apt:0,ar:2,arbitrari:3,argument:[3,4,5],as_dictionari:[7,8],avail:[2,4,5,7],available_environ:7,available_gpu:7,availableneuron:[7,8],base:[2,3,4,5,6,7,8],bashrc:0,batch:8,batch_siz:[7,8],becom:[6,7],being:8,bin:0,bool:[2,5,7,8],call:5,care:5,cart_pol:[2,7,8],cartpol:[2,7,8],cd:0,clear:3,clone:[0,5],column:3,com:0,command:[7,8],complet:7,comput:[5,6],contain:[3,4],convert:[3,7,8],correspond:8,cpu:8,creat:[0,3,7],cuda:[7,8],current:[2,6],current_lay:6,data:[3,4,5,8],datafram:3,deep_q:[7,8],deepq:5,defin:5,desired_spars:6,devic:[7,8],dict:[7,8],dictionari:[7,8],distribut:[4,7],distribute_to_lay:4,distribute_to_neuron:4,doesn:3,download:0,dure:[7,8],e:0,each:[4,7],echo:0,element:3,embedding_s:5,enumer:2,environ:[0,1,4,5,7,8],episod:[2,8],episode_reward:2,evenli:7,everi:[5,8],exampl:5,execut:[4,7],exist:3,fals:[2,7,8],follow:2,former:5,forward:5,from:[2,3,4,5],from_most_rec:3,get:[0,2,3],get_return:5,git:0,github:0,gpu:[7,8],group:7,gymenviron:[7,8],gymnasium:2,ha:[7,8],have:[4,7],histori:[1,4,5],hook:5,id:[7,8],ignor:5,individu:[7,8],inform:5,input_s:5,instal:1,instanc:5,instead:5,intern:[3,5],is_don:7,jobs_per_gpu:7,kei:[3,4],keyword:[3,5],kwarg:[3,4,5],last:[6,7,8],latter:5,layer:[6,7,8],layer_output:4,learn:[4,5,7,8],learning_r:[4,5,7,8],line:[7,8],list:[3,4,7],liter:8,local:[4,5],m:0,main:7,max:3,maximum_episod:[7,8],mkdir:0,modul:5,mountain_car:[2,8],mountaincar:[2,8],multi:0,multi_agent_network:1,multiagentnetwork:7,n:8,name:[2,3],narla:0,need:[0,5],network:[0,7,8],neuron:[4,6,7,8],neuron_typ:[7,8],next:6,next_lay:6,nn:5,none:6,number:[2,4,5,7,8],number_of_act:[2,4,5],number_of_lay:[4,7,8],number_of_neuron:4,number_of_neurons_per_lay:[4,7,8],object:[2,3,4,5,6,7,8],observ:[2,4,5],observation_s:[2,4,5],one:[2,5,7,8],onli:[7,8],output:4,output_s:5,overridden:5,p:0,packag:0,paramet:[2,3,4,5,6,7],pass:[5,7],path:8,per:[7,8],perform:5,phase:4,pip:0,policy_gradi:8,policygradi:5,popen:7,prefix:8,process:7,produc:2,product:7,project:0,properti:[2,4,5],put:[7,8],py:7,python3:0,python_environ:0,pytorch:5,rang:7,rate:[4,5,7,8],receiv:[4,5],recip:5,record:[3,4,5],regist:5,render:[2,7,8],reset:2,result:8,results_directori:[7,8],reward:[1,2,7,8],reward_typ:[7,8],run:[5,7,8],runner:1,s:[2,4,5,6],sampl:[2,3],sample_histori:5,sample_s:3,save:8,save_everi:[7,8],set:[1,7],shape:2,should:5,silent:5,sinc:5,singl:2,site:0,size:[2,3,4,5,8],sourc:[2,3,4,5,6,7,8],space:2,sparsiti:6,step:[2,8],storag:3,storage_s:3,store:[3,4,5],str:[3,7,8],string:[7,8],subclass:5,sudo:0,support:0,system:0,t:3,take:[2,4,5],taken:2,task_reward:[7,8],tensor:[2,3,4,5,6],termin:2,thei:7,them:5,thi:5,time:2,to_command_str:[7,8],to_data_fram:3,torch:[4,5],total:[2,7,8],train:[3,5,7,8],trial:8,trial_id:[7,8],tupl:[2,5],type:[2,3,4,5,6,7,8],uniqu:8,updat:5,update_target_network:5,us:[3,5,7,8],v0:[2,8],v1:[2,7,8],valid:2,valu:[2,3,7],venv:0,virtual:0,visual:[2,8],what:[7,8],which:[4,5],within:5,word:[3,4],wrapper:2,x:5,yet:3,you:0},titles:["Installing","NaRLA: Neurons as Reinforcement Learning Agents","narla.environments","narla.history","narla.multi_agent_network","narla.neurons","narla.rewards","narla.runner","narla.Settings","NaRLA: Neurons as Reinforcement Learning Agents"],titleterms:{actionspac:2,activeneuron:6,actor_crit:5,agent:[1,9],availableenviron:2,deep_q:5,document:1,environ:2,get:1,gymenviron:2,histori:3,instal:0,job:7,layer:4,layerspars:6,learn:[1,9],multi_agent_network:4,multiagentnetwork:4,narla:[1,2,3,4,5,6,7,8,9],network:5,neuron:[1,5,9],policy_gradi:5,reinforc:[1,9],reward:6,runner:7,runnerset:7,set:8,start:1}})