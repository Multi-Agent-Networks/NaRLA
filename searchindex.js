Search.setIndex({docnames:["getting_started/installing","index","narla/environments","narla/history","narla/multi_agent_network","narla/neurons","narla/rewards","narla/runner","narla/settings","welcome"],envversion:{"sphinx.domains.c":2,"sphinx.domains.changeset":1,"sphinx.domains.citation":1,"sphinx.domains.cpp":4,"sphinx.domains.index":1,"sphinx.domains.javascript":2,"sphinx.domains.math":2,"sphinx.domains.python":3,"sphinx.domains.rst":2,"sphinx.domains.std":2,"sphinx.ext.intersphinx":1,"sphinx.ext.todo":2,"sphinx.ext.viewcode":1,nbsphinx:4,sphinx:56},filenames:["getting_started/installing.rst","index.rst","narla/environments.rst","narla/history.rst","narla/multi_agent_network.rst","narla/neurons.rst","narla/rewards.rst","narla/runner.rst","narla/settings.rst","welcome.rst"],objects:{"narla.environments":[[2,0,1,"","AvailableEnvironments"],[2,1,1,"","Environment"],[2,1,1,"","GymEnvironment"],[2,0,1,"","GymEnvironments"]],"narla.environments.Environment":[[2,2,1,"","action_space"],[2,2,1,"","episode_reward"],[2,2,1,"","observation_size"],[2,3,1,"","reset"],[2,3,1,"","step"]],"narla.environments.GymEnvironment":[[2,2,1,"","observation_size"],[2,3,1,"","reset"],[2,3,1,"","step"]],"narla.environments.GymEnvironments":[[2,4,1,"","CART_POLE"],[2,4,1,"","MOUNTAIN_CAR"]]},objnames:{"0":["py","enum","Python enum"],"1":["py","class","Python class"],"2":["py","property","Python property"],"3":["py","method","Python method"],"4":["py","attribute","Python attribute"]},objtypes:{"0":"py:enum","1":"py:class","2":"py:property","3":"py:method","4":"py:attribute"},terms:{"8":0,"class":2,"enum":2,"float":2,"int":2,"return":2,"true":2,If:2,access:2,action:2,action_spac:2,advanc:2,agent:0,alia:0,an:2,apt:0,ar:2,base:2,bashrc:0,bin:0,bool:2,cart_pol:2,cartpol:2,cd:0,clone:0,com:0,creat:0,current:2,download:0,e:0,echo:0,enumer:2,environ:[0,1],episod:2,episode_reward:2,fals:2,follow:2,from:2,get:[0,2],git:0,github:0,gymnasium:2,histori:1,instal:1,m:0,mkdir:0,mountain_car:2,mountaincar:2,multi:0,multi_agent_network:1,name:2,narla:0,need:0,network:0,object:2,observ:2,observation_s:2,one:2,p:0,packag:0,paramet:2,pep517:0,pip:0,produc:2,project:0,properti:2,python3:0,python_environ:0,render:2,reset:2,reward:[1,2],runner:1,s:2,set:1,singl:2,site:0,size:2,sourc:2,step:2,sudo:0,support:0,system:0,take:2,taken:2,tensor:2,termin:2,time:2,total:2,tupl:2,type:2,us:0,v0:2,v1:2,valid:2,valu:2,venv:0,virtual:0,visual:2,wrapper:2,you:0},titles:["Installing","NaRLA: Neurons as Reinforcement Learning Agents","narla.environments","narla.history","narla.multi_agent_network","narla.neurons","narla.rewards","narla.runner","narla.settings","NaRLA: Neurons as Reinforcement Learning Agents"],titleterms:{actionspac:2,activeneuron:6,actor_crit:5,agent:[1,9],availableenviron:2,biologicalreward:6,deep_q:5,document:1,environ:2,get:1,gymenviron:2,histori:3,instal:0,job:7,layer:4,layerset:4,layerspars:6,learn:[1,9],multi_agent_network:4,multiagentnetwork:4,multiagentnetworkset:4,narla:[1,2,3,4,5,6,7,8,9],network:5,neuron:[1,5,9],neuronset:5,neurontyp:5,policy_gradi:5,reinforc:[1,9],reward:6,rewardtyp:6,runner:7,runnerset:7,set:8,start:1,trialset:8}})